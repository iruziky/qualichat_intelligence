# Qualichat Intelligence

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python)

Backend inteligente projetado para potencializar o Qualichat com capacidades de IA conversacional avanÃ§ada. Utiliza uma arquitetura de **GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (RAG)** orquestrada com **LangGraph** para criar fluxos de conversa com estado, modulares e eficientes.

---

## âœ¨ Core Features

- **Fluxo Conversacional com Estado:** Utiliza LangGraph para gerenciar o estado da conversa, permitindo interaÃ§Ãµes mais complexas e contextuais.
- **GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (RAG):** Enriquece as respostas do LLM com informaÃ§Ãµes de um banco de dados vetorial, garantindo respostas mais precisas e baseadas em conhecimento.
- **Suporte a MÃºltiplos LLMs e Embeddings:** Integrado com LiteLLM, permitindo a troca flexÃ­vel entre diferentes provedores de modelos (OpenAI, Anthropic, etc.) atravÃ©s de configuraÃ§Ã£o.
- **PersistÃªncia Vetorial Local:** Usa ChromaDB para armazenar e consultar embeddings de forma eficiente e local.
- **Gerenciamento Robusto:** Estruturado com Poetry para gerenciamento de dependÃªncias e Pydantic para validaÃ§Ã£o de configuraÃ§Ãµes.

---

## ğŸ›ï¸ Arquitetura

O sistema opera com base em um pipeline RAG orquestrado. Quando uma pergunta Ã© recebida, o fluxo Ã© o seguinte:

1.  **RecuperaÃ§Ã£o (RetrievalService):** A pergunta do usuÃ¡rio Ã© transformada em um embedding vetorial. Esse embedding Ã© usado para consultar o ChromaDB e encontrar os documentos ou trechos de conhecimento mais relevantes.
2.  **Enriquecimento (RAGPipeline):** Os documentos recuperados (contexto) sÃ£o combinados com a pergunta original em um prompt otimizado.
3.  **GeraÃ§Ã£o (LLMService):** O prompt enriquecido Ã© enviado ao Large Language Model (LLM) para gerar uma resposta final, que Ã© contextualizada e precisa.
4.  **OrquestraÃ§Ã£o (ConversationGraph):** Todo o processo Ã© gerenciado como um grafo de estados pelo LangGraph, garantindo um fluxo de dados claro e a capacidade de expandir o sistema com novos passos ou lÃ³gicas condicionais no futuro.

---

## ğŸš€ Getting Started

Siga os passos abaixo para configurar e executar o projeto localmente.

### PrÃ©-requisitos

- Python 3.10+
- [Poetry](https://python-poetry.org/docs/#installation) para gerenciamento de dependÃªncias.

### 1. InstalaÃ§Ã£o

Primeiro, clone o repositÃ³rio e instale as dependÃªncias:

```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd qualichat_intelligence
poetry install
```

### 2. ConfiguraÃ§Ã£o do Ambiente

O projeto utiliza um arquivo `.env` para gerenciar chaves de API e outras configuraÃ§Ãµes.

1.  Copie o arquivo de exemplo:
    ```bash
    cp .env.example .env
    ```

2.  Abra o arquivo `.env` e adicione sua chave de API do provedor de LLM. Atualmente, ele estÃ¡ configurado para a OpenAI:

    ```dotenv
    # .env
    OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    DEFAULT_MODEL="gpt-4"
    VECTOR_DB_PATH="./chroma_db"
    ```

---

## â–¶ï¸ Usage

Para interagir com o assistente, utilize o terminal interativo. Ele permite testar o pipeline de conversaÃ§Ã£o de ponta a ponta.

Execute o seguinte comando na raiz do projeto:

```bash
poetry run python run.py
```

O script serÃ¡ iniciado e vocÃª verÃ¡ um prompt `>`. Simplesmente digite sua pergunta e pressione Enter. Para sair, digite `exit` ou `quit`.

---

## ğŸ“‚ Estrutura do Projeto

```
qualichat_intelligence/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/         # ConfiguraÃ§Ã£o, logger e factories
â”‚   â”œâ”€â”€ graphs/       # LÃ³gica de orquestraÃ§Ã£o com LangGraph
â”‚   â”œâ”€â”€ models/       # Modelos de dados (Pydantic)
â”‚   â”œâ”€â”€ repositories/ # Camada de acesso a dados (ChromaDB)
â”‚   â””â”€â”€ services/     # LÃ³gica de negÃ³cio (LLM, Embeddings, RAG)
â”‚
â”œâ”€â”€ tests/            # Testes automatizados
â”œâ”€â”€ .env.example      # Arquivo de exemplo para variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore        # Arquivos e pastas a serem ignorados pelo Git
â”œâ”€â”€ pyproject.toml    # DefiniÃ§Ãµes do projeto e dependÃªncias (Poetry)
â””â”€â”€ run.py            # Ponto de entrada para o terminal interativo
```

---

## ğŸ—ºï¸ Roadmap

- [ ] Implementar uma API (FastAPI) para expor o serviÃ§o de chat.
- [ ] Adicionar um serviÃ§o de ingestÃ£o de documentos para popular o ChromaDB.
- [ ] Expandir o `ConversationGraph` com mais nÃ³s para ferramentas e lÃ³gicas complexas.
- [ ] Criar um conjunto de testes unitÃ¡rios e de integraÃ§Ã£o.

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a LicenÃ§a MIT.